const availableModels = [
    {
        "organization": "Meta",
        "model_name": "Code Llama Python (70B)",
        "model_string_for_api": "codellama/CodeLlama-70b-Python-hf",
        "context_length": 4096,
        "description": "Advanced Python code generation for large-scale tasks.",
        "modeltype": "Code",
        "response_time": "Slower",
        "cost": "High",
        "known_for": "Large-scale Python code generation",
        "specialty": "Complex and advanced Python code generation",
        "use_suggestion": "Handling large, intricate Python projects."
    },
    {
        "organization": "Meta",
        "model_name": "Code Llama Python (34B)",
        "model_string_for_api": "codellama/CodeLlama-34b-Python-hf",
        "context_length": 16384,
        "description": "Optimized Python model for complex tasks with larger context.",
        "modeltype": "Code",
        "response_time": "Medium",
        "cost": "Medium",
        "known_for": "Handling complex Python tasks",
        "specialty": "Optimized for large context code generation",
        "use_suggestion": "Best for medium-sized Python development tasks."
    },
    {
        "organization": "Meta",
        "model_name": "Code Llama Python (13B)",
        "model_string_for_api": "codellama/CodeLlama-13b-Python-hf",
        "context_length": 16384,
        "description": "Efficient Python model for diverse tasks with wide context.",
        "modeltype": "Code",
        "response_time": "Faster",
        "cost": "Cheaper",
        "known_for": "Efficient Python task performance",
        "specialty": "Diverse Python tasks with a large context",
        "use_suggestion": "Ideal for generating Python code snippets and automating tasks."
    },
    {
        "organization": "Meta",
        "model_name": "Code Llama Python (7B)",
        "model_string_for_api": "codellama/CodeLlama-7b-Python-hf",
        "context_length": 16384,
        "description": "Small Python model for fast code generation and lower resources.",
        "modeltype": "Code",
        "response_time": "Faster",
        "cost": "Cheaper",
        "known_for": "Fast code generation with lower resource usage",
        "specialty": "Small Python projects",
        "use_suggestion": "Use for lightweight Python coding tasks."
    },
    {
        "organization": "Phind",
        "model_name": "Phind Code LLaMA v2 (34B)",
        "model_string_for_api": "Phind/Phind-CodeLlama-34B-v2",
        "context_length": 16384,
        "description": "Phind's model for efficient Python code generation and search.",
        "modeltype": "Code",
        "response_time": "Medium",
        "cost": "Medium",
        "known_for": "Efficient Python code generation",
        "specialty": "Code generation with search optimization",
        "use_suggestion": "Good for integrating code generation with search features."
    },
    {
        "organization": "WizardLM",
        "model_name": "WizardCoder Python v1.0 (34B)",
        "model_string_for_api": "WizardLM/WizardCoder-Python-34B-V1.0",
        "context_length": 8192,
        "description": "High-performance Python code generation model for complex tasks.",
        "modeltype": "Code",
        "response_time": "Slower",
        "cost": "High",
        "known_for": "Python-focused code generation",
        "specialty": "High-performance Python code generation for complex tasks",
        "use_suggestion": "Suitable for heavy Python programming tasks requiring precision."
    },
    {
        "organization": "WizardLM",
        "model_name": "WizardCoder v1.0 (15B)",
        "model_string_for_api": "WizardLM/WizardCoder-15B-V1.0",
        "context_length": 8192,
        "description": "Mid-sized model focused on Python programming and efficient outputs.",
        "modeltype": "Code",
        "response_time": "Medium",
        "cost": "Medium",
        "known_for": "Efficient outputs for Python programming",
        "specialty": "Mid-sized model for Python development",
        "use_suggestion": "Use for moderate Python coding and refactoring tasks."
    },

    //chat


    {
        "organization": "01.AI",
        "model_name": "Yi Chat (34B)",
        "model_string_for_api": "zero-one-ai/Yi-34B-Chat",
        "context_length": 4096,
        "description": "AI model for advanced chat interactions.",
        "modeltype": "Chat",
        "response_time": "Medium",
        "cost": "Medium",
        "known_for": "Advanced chat interactions",
        "specialty": "Efficient chat model for conversational tasks",
        "use_suggestion": "Perfect for building interactive AI chatbots."
    },
    {
        "organization": "Allen AI",
        "model_name": "OLMo-7B-Instruct",
        "model_string_for_api": "allenai/OLMo-7B-Instruct",
        "context_length": 4096,
        "description": "Instruction-based chat model for various conversational tasks.",
        "modeltype": "Chat",
        "response_time": "Faster",
        "cost": "Medium",
        "known_for": "Instruction-based conversational tasks",
        "specialty": "Handling diverse instruction-tuned chat tasks",
        "use_suggestion": "Ideal for customer support or instructional chatbots."
    },



    {
        "organization": "Allen AI",
        "model_name": "OLMo-7B-Twin-2T",
        "model_string_for_api": "allenai/OLMo-7B-Twin-2T",
        "context_length": 4096,
        "description": "Advanced chat model with twin capabilities for better understanding.",
        "modeltype": "Chat",
        "response_time": "Medium",
        "cost": "Medium",
        "known_for": "Advanced chat with twin capabilities",
        "specialty": "Better contextual understanding and conversational flows",
        "use_suggestion": "Use for customer service or chat applications needing better context."
    },
    {
        "organization": "Allen AI",
        "model_name": "OLMo-7B",
        "model_string_for_api": "allenai/OLMo-7B",
        "context_length": 4096,
        "description": "Standard chat model from Allen AI for conversational tasks.",
        "modeltype": "Chat",
        "response_time": "Faster",
        "cost": "Medium",
        "known_for": "Standard chat model for conversational tasks",
        "specialty": "General-purpose chat",
        "use_suggestion": "Great for small talk, storytelling, and basic conversations."
    },
    {
        "organization": "Austism",
        "model_name": "Chronos Hermes (13B)",
        "model_string_for_api": "Austism/chronos-hermes-13b",
        "context_length": 2048,
        "description": "Chat model for advanced interactions with Chronos technology.",
        "modeltype": "Chat",
        "response_time": "Medium",
        "cost": "Medium",
        "known_for": "Chronos technology-based chat",
        "specialty": "Advanced interactions",
        "use_suggestion": "Suitable for long, detailed conversations and discussions."
    },
    {
        "organization": "Cognitive Computations",
        "model_name": "Dolphin-2.5 Mixtral (8x7B)",
        "model_string_for_api": "cognitivecomputations/dolphin-2.5-mixtral-8x7b",
        "context_length": 4096,
        "description": "High-performance chat model with Dolphin-2.5 technology.",
        "modeltype": "Chat",
        "response_time": "Slower",
        "cost": "High",
        "known_for": "High-performance Dolphin technology",
        "specialty": "Complex conversational tasks",
        "use_suggestion": "Ideal for deep research discussions or technical inquiries."
    },
    {
        "organization": "DeepSeek",
        "model_name": "Deepseek Coder Instruct (33B)",
        "model_string_for_api": "deepseek-ai/deepseek-coder-33b-instruct",
        "context_length": 16384,
        "description": "Chat model focused on code and instruction-based interactions.",
        "modeltype": "Chat",
        "response_time": "Slower",
        "cost": "High",
        "known_for": "Code and instruction-based interaction",
        "specialty": "Complex instruction-based code generation and chat",
        "use_suggestion": "Great for tech tutorials or AI programming guides."
    },
    {
        "organization": "DeepSeek",
        "model_name": "Deepseek LLM Chat (67B)",
        "model_string_for_api": "deepseek-ai/deepseek-llm-67b-chat",
        "context_length": 4096,
        "description": "Large LLM designed for chat-based applications.",
        "modeltype": "Chat",
        "response_time": "Slower",
        "cost": "High",
        "known_for": "Large LLM for chat applications",
        "specialty": "Handling long and complex conversations",
        "use_suggestion": "Use for problem-solving and advisory roles in tech areas."
    },
    {
        "organization": "garage-bAInd",
        "model_name": "Platypus2 Instruct (70B)",
        "model_string_for_api": "garage-bAInd/Platypus2-70B-instruct",
        "context_length": 4096,
        "description": "Large-scale instruction-based chat model for complex tasks.",
        "modeltype": "Chat",
        "response_time": "Slower",
        "cost": "High",
        "known_for": "Large-scale instruction-based chat model",
        "specialty": "Complex instruction-based conversations",
        "use_suggestion": "Ideal for handling high-level instruction-based tasks."
    },
    {
        "organization": "Google",
        "model_name": "Gemma Instruct (2B)",
        "model_string_for_api": "google/gemma-2b-it",
        "context_length": 8192,
        "description": "Google's model for instruction-based chat tasks.",
        "modeltype": "Chat",
        "response_time": "Faster",
        "cost": "Free",
        "known_for": "Compact instruction model",
        "specialty": "Instruction-based conversational tasks",
        "use_suggestion": "Use for educational chatbots or lightweight conversation needs."
    },
    {
        "organization": "Google",
        "model_name": "Gemma Instruct (7B)",
        "model_string_for_api": "google/gemma-7b-it",
        "context_length": 8192,
        "description": "A larger version of Google's Gemma for chat-based tasks.",
        "modeltype": "Chat",
        "response_time": "Medium",
        "cost": "Medium",
        "known_for": "Google’s instruction model for larger tasks",
        "specialty": "Handling instruction-heavy chat tasks",
        "use_suggestion": "Great for academic assistance and tutoring applications."
    },
    {
        "organization": "Gryphe",
        "model_name": "MythoMax-L2 (13B)",
        "model_string_for_api": "Gryphe/MythoMax-L2-13b",
        "context_length": 4096,
        "description": "Chat model for deep mythological-inspired conversations.",
        "modeltype": "Chat",
        "response_time": "Medium",
        "cost": "Medium",
        "known_for": "Mythological-inspired conversations",
        "specialty": "Creative and deep philosophical discussions",
        "use_suggestion": "Perfect for interactive storytelling and mythological chat."
    },





    {
        "organization": "LM Sys",
        "model_name": "Vicuna v1.5 (13B)",
        "model_string_for_api": "lmsys/vicuna-13b-v1.5",
        "context_length": 4096,
        "description": "LM Sys's chat model for general conversational tasks.",
        "modeltype": "Chat",
        "response_time": "Faster",
        "cost": "Medium",
        "known_for": "Efficient conversational tasks",
        "specialty": "General-purpose chat",
        "use_suggestion": "Use for small talk, jokes, or casual conversations."
    },
    {
        "organization": "LM Sys",
        "model_name": "Vicuna v1.5 (7B)",
        "model_string_for_api": "lmsys/vicuna-7b-v1.5",
        "context_length": 4096,
        "description": "Smaller version of Vicuna optimized for chat tasks.",
        "modeltype": "Chat",
        "response_time": "Faster",
        "cost": "Cheaper",
        "known_for": "Smaller, efficient chat model",
        "specialty": "Fast, lightweight conversations",
        "use_suggestion": "Great for quick responses in everyday chatbots."
    },
    {
        "organization": "Meta",
        "model_name": "Code Llama Instruct (13B)",
        "model_string_for_api": "codellama/CodeLlama-13b-Instruct-hf",
        "context_length": 16384,
        "description": "Meta's Code Llama for instruction-based code and chat tasks.",
        "modeltype": "Chat",
        "response_time": "Faster",
        "cost": "Cheaper",
        "known_for": "Code instruction-based tasks",
        "specialty": "Handling simple code-related instructions",
        "use_suggestion": "Use for programming tutorials or beginner-level coding guides."
    },
    {
        "organization": "Meta",
        "model_name": "Code Llama Instruct (34B)",
        "model_string_for_api": "codellama/CodeLlama-34b-Instruct-hf",
        "context_length": 16384,
        "description": "Meta's larger Code Llama model for code instructions.",
        "modeltype": "Chat",
        "response_time": "Medium",
        "cost": "Medium",
        "known_for": "Advanced instruction-based code generation",
        "specialty": "Handling complex code tasks",
        "use_suggestion": "Great for medium to large-scale programming projects."
    },
    {
        "organization": "Meta",
        "model_name": "Code Llama Instruct (70B)",
        "model_string_for_api": "codellama/CodeLlama-70b-Instruct-hf",
        "context_length": 4096,
        "description": "Large-scale instruction model for code and chat tasks.",
        "modeltype": "Chat",
        "response_time": "Slower",
        "cost": "High",
        "known_for": "Large-scale code and instruction model",
        "specialty": "Complex code generation",
        "use_suggestion": "Ideal for high-level coding assistance or research projects."
    },
    {
        "organization": "Meta",
        "model_name": "Code Llama Instruct (7B)",
        "model_string_for_api": "codellama/CodeLlama-7b-Instruct-hf",
        "context_length": 16384,
        "description": "Compact Code Llama for chat and code instruction tasks.",
        "modeltype": "Chat",
        "response_time": "Faster",
        "cost": "Cheaper",
        "known_for": "Compact code instruction model",
        "specialty": "Simple and fast code generation",
        "use_suggestion": "Best for lightweight coding tasks or quick code snippets."
    },
    {
        "organization": "Meta",
        "model_name": "LLaMA-2 Chat (70B)",
        "model_string_for_api": "meta-llama/Llama-2-70b-chat-hf",
        "context_length": 4096,
        "description": "Meta's LLaMA-2 optimized for chat-based applications.",
        "modeltype": "Chat",
        "response_time": "Medium",
        "cost": "High",
        "known_for": "Advanced conversational AI",
        "specialty": "Handling various conversational tasks",
        "use_suggestion": "Great for interactive chatbots or customer service agents."
    },
    {
        "organization": "Meta",
        "model_name": "LLaMA-3.1 Chat (405B)",
        "model_string_for_api": "meta-llama/Meta-Llama-3.1-405B-Instruct-Turbo",
        "context_length": 4096,
        "description": "Meta's LLaMA-3.1 with a large context window for chat.",
        "modeltype": "Chat",
        "response_time": "Slower",
        "cost": "High",
        "known_for": "Large-scale instruction-based conversational AI",
        "specialty": "Handling large context conversational tasks",
        "use_suggestion": "Use for high-level instruction-based tasks in large contexts."
    },
    {
        "organization": "Meta",
        "model_name": "LLaMA-3.1 Chat (70B)",
        "model_string_for_api": "meta-llama/Meta-Llama-3.1-70B-Instruct-Turbo",
        "context_length": 128000,
        "description": "Meta's next-gen LLaMA-3.1 with massive context capabilities.",
        "modeltype": "Chat",
        "response_time": "Medium",
        "cost": "High",
        "known_for": "Massive context capabilities",
        "specialty": "High-performance chat tasks",
        "use_suggestion": "Best for handling long conversational threads or complex tasks."
    },


    //

    {
        "organization": "Meta",
        "model_name": "LLaMA-3.1 Chat (8B)",
        "model_string_for_api": "meta-llama/Meta-Llama-3.1-8B-Instruct-Turbo",
        "context_length": 128000,
        "description": "Meta's LLaMA-3.1 for chat, with 128K context length.",
        "modeltype": "Chat",
        "response_time": "Faster",
        "cost": "High",
        "known_for": "Massive context length support",
        "specialty": "Handling long-form instruction-based tasks",
        "use_suggestion": "Ideal for long technical conversations or detailed code instructions."
    },



    {
        "organization": "Meta",
        "model_name": "LLaMA-2 Chat (13B)",
        "model_string_for_api": "meta-llama/Llama-2-13b-chat-hf",
        "context_length": 4096,
        "description": "Meta's LLaMA-2 Chat model for advanced conversational tasks.",
        "modeltype": "Chat",
        "response_time": "Medium",
        "cost": "Medium",
        "known_for": "Meta's conversational AI",
        "specialty": "General-purpose conversational tasks",
        "use_suggestion": "Great for interactive tutoring or conversation-based apps."
    },
    {
        "organization": "Meta",
        "model_name": "LLaMA-2 Chat (7B)",
        "model_string_for_api": "meta-llama/Llama-2-7b-chat-hf",
        "context_length": 4096,
        "description": "Meta's smaller LLaMA-2 model for efficient chat interactions.",
        "modeltype": "Chat",
        "response_time": "Faster",
        "cost": "Cheaper",
        "known_for": "Smaller version for efficient chat",
        "specialty": "General-purpose chat with fast responses",
        "use_suggestion": "Use for lightweight chatbots or personal assistants."
    },
    {
        "organization": "Mistralai",
        "model_name": "Mistral (7B) Instruct v0.1",
        "model_string_for_api": "mistralai/Mistral-7B-Instruct-v0.1",
        "context_length": 4096,
        "description": "Mistral model tuned for instruction-based tasks in chat.",
        "modeltype": "Chat",
        "response_time": "Faster",
        "cost": "Cheaper",
        "known_for": "Instruction-based conversational tasks",
        "specialty": "Handling instruction-driven conversations",
        "use_suggestion": "Good for educational tutoring or simple conversational guidance."
    },
    {
        "organization": "Mistralai",
        "model_name": "Mistral (7B) Instruct v0.2",
        "model_string_for_api": "mistralai/Mistral-7B-Instruct-v0.2",
        "context_length": 32768,
        "description": "Mistral v0.2, improved version with large context length.",
        "modeltype": "Chat",
        "response_time": "Medium",
        "cost": "Medium",
        "known_for": "Improved version with larger context length",
        "specialty": "Handling medium to large context instruction tasks",
        "use_suggestion": "Use for academic and technical instructions with larger context needs."
    },
    {
        "organization": "Mistralai",
        "model_name": "Mixtral-8x7B Instruct v0.1 (46.7B)",
        "model_string_for_api": "mistralai/Mixtral-8x7B-Instruct-v0.1",
        "context_length": 32768,
        "description": "Combination of 8 Mistral models for high-performance instruction.",
        "modeltype": "Chat",
        "response_time": "Slower",
        "cost": "High",
        "known_for": "Combination of 8 Mistral models",
        "specialty": "High-performance instruction tasks",
        "use_suggestion": "Great for complex educational or coding instruction tasks."
    },
    {
        "organization": "NousResearch",
        "model_name": "Nous Capybara v1.9 (7B)",
        "model_string_for_api": "NousResearch/Nous-Capybara-7B-V1p9",
        "context_length": 8192,
        "description": "NousResearch's Capybara model for diverse chat tasks.",
        "modeltype": "Chat",
        "response_time": "Medium",
        "cost": "Medium",
        "known_for": "Handling diverse chat tasks",
        "specialty": "Versatile conversational tasks",
        "use_suggestion": "Use for casual conversations, storytelling, or tutoring."
    },
    {
        "organization": "NousResearch",
        "model_name": "Nous Hermes 2 - Mixtral 8x7B-DPO (46.7B)",
        "model_string_for_api": "NousResearch/Nous-Hermes-2-Mixtral-8x7B-DPO",
        "context_length": 32768,
        "description": "DPO variant of Nous Hermes 2, combining multiple models.",
        "modeltype": "Chat",
        "response_time": "Slower",
        "cost": "High",
        "known_for": "Handling multitasking in chat",
        "specialty": "High-performance multitasking",
        "use_suggestion": "Ideal for complex chatbots or advanced support systems."
    },
    {
        "organization": "NousResearch",
        "model_name": "Nous Hermes 2 - Mixtral (8x7B) SFT (46.7B)",
        "model_string_for_api": "NousResearch/Nous-Hermes-2-Mixtral-8x7B-SFT",
        "context_length": 32768,
        "description": "SFT variant of Nous Hermes 2, focused on multitasking.",
        "modeltype": "Chat",
        "response_time": "Slower",
        "cost": "High",
        "known_for": "Handling multitasking and large tasks",
        "specialty": "Efficient at multitasking with large contexts",
        "use_suggestion": "Use for managing multiple chat conversations simultaneously."
    },
    {
        "organization": "NousResearch",
        "model_name": "Nous Hermes LLaMA-2 (7B)",
        "model_string_for_api": "NousResearch/Nous-Hermes-llama-2-7b",
        "context_length": 4096,
        "description": "Nous Hermes model based on LLaMA-2 architecture.",
        "modeltype": "Chat",
        "response_time": "Medium",
        "cost": "Medium",
        "known_for": "LLaMA-2 architecture for efficient chat",
        "specialty": "Handling small to medium chat tasks",
        "use_suggestion": "Good for tutoring or providing step-by-step guidance."
    },
    {
        "organization": "NousResearch",
        "model_name": "Nous Hermes LLaMA-2 (13B)",
        "model_string_for_api": "NousResearch/Nous-Hermes-Llama2-13b",
        "context_length": 4096,
        "description": "Nous Hermes variant based on LLaMA-2 with 13B parameters.",
        "modeltype": "Chat",
        "response_time": "Medium",
        "cost": "Medium",
        "known_for": "Large parameter chat model",
        "specialty": "Handling large conversational tasks",
        "use_suggestion": "Use for detailed conversations or interactive chatbots."
    },





    {
        "organization": "NousResearch",
        "model_name": "Nous Hermes 2 Yi (34B)",
        "model_string_for_api": "NousResearch/Nous-Hermes-2-Yi-34B",
        "context_length": 4096,
        "description": "Nous Hermes Yi variant for complex chat tasks.",
        "modeltype": "Chat",
        "response_time": "Slower",
        "cost": "High",
        "known_for": "Yi-34B chat specialization",
        "specialty": "Handling complex chat interactions",
        "use_suggestion": "Great for business chatbots or customer service with high interaction needs."
    },
    {
        "organization": "OpenChat",
        "model_name": "OpenChat 3.5 (7B)",
        "model_string_for_api": "openchat/openchat-3.5-1210",
        "context_length": 8192,
        "description": "OpenChat's GPT-based model for versatile conversational tasks.",
        "modeltype": "Chat",
        "response_time": "Faster",
        "cost": "Cheaper",
        "known_for": "Efficient chat-based interactions",
        "specialty": "General-purpose conversations",
        "use_suggestion": "Use for fast, responsive chatbots or personal assistants."
    },
    {
        "organization": "OpenOrca",
        "model_name": "OpenOrca Mistral (7B) 8k",
        "model_string_for_api": "Open-Orca/Mistral-7B-OpenOrca",
        "context_length": 8192,
        "description": "Mistral-based OpenOrca model with extended 8K context.",
        "modeltype": "Chat",
        "response_time": "Faster",
        "cost": "Cheaper",
        "known_for": "Extended context chat model",
        "specialty": "Handling larger conversational contexts",
        "use_suggestion": "Good for dynamic conversations needing a longer context."
    },
    {
        "organization": "Qwen",
        "model_name": "Qwen Chat (7B)",
        "model_string_for_api": "togethercomputer/Qwen-7B-Chat",
        "context_length": 8192,
        "description": "Qwen's 7B model optimized for efficient conversational tasks.",
        "modeltype": "Chat",
        "response_time": "Faster",
        "cost": "Cheaper",
        "known_for": "Efficient and responsive chat",
        "specialty": "Optimized for small conversations",
        "use_suggestion": "Perfect for quick, responsive small talk or simple conversations."
    },
    {
        "organization": "Qwen",
        "model_name": "Qwen 1.5 Chat (0.5B)",
        "model_string_for_api": "Qwen/Qwen1.5-0.5B-Chat",
        "context_length": 32768,
        "description": "Lightweight Qwen model optimized for conversational tasks.",
        "modeltype": "Chat",
        "response_time": "Faster",
        "cost": "Free",
        "known_for": "Lightweight conversational tasks",
        "specialty": "Handling small, fast conversations",
        "use_suggestion": "Use for quick replies or chatbots with low complexity needs."
    },
    {
        "organization": "Qwen",
        "model_name": "Qwen 1.5 Chat (1.8B)",
        "model_string_for_api": "Qwen/Qwen1.5-1.8B-Chat",
        "context_length": 32768,
        "description": "Mid-sized Qwen model optimized for diverse conversational tasks.",
        "modeltype": "Chat",
        "response_time": "Faster",
        "cost": "Cheaper",
        "known_for": "Efficient chat model for mid-sized tasks",
        "specialty": "Handling small to medium conversations",
        "use_suggestion": "Use for casual chatbots or medium interaction tasks."
    },
    {
        "organization": "Qwen",
        "model_name": "Qwen 1.5 Chat (4B)",
        "model_string_for_api": "Qwen/Qwen1.5-4B-Chat",
        "context_length": 32768,
        "description": "Larger Qwen model optimized for advanced conversations.",
        "modeltype": "Chat",
        "response_time": "Medium",
        "cost": "Medium",
        "known_for": "Optimized chat for larger tasks",
        "specialty": "Handling larger conversations efficiently",
        "use_suggestion": "Best for managing more in-depth conversations or moderate business chat."
    },
    {
        "organization": "Qwen",
        "model_name": "Qwen 1.5 Chat (7B)",
        "model_string_for_api": "Qwen/Qwen1.5-7B-Chat",
        "context_length": 32768,
        "description": "Qwen's 7B model with extended context and enhanced chat performance.",
        "modeltype": "Chat",
        "response_time": "Medium",
        "cost": "Medium",
        "known_for": "Handling diverse conversational tasks",
        "specialty": "Efficient at longer, more complex conversations",
        "use_suggestion": "Great for use in technical support or deeper conversations."
    },
    {
        "organization": "Qwen",
        "model_name": "Qwen 1.5 Chat (14B)",
        "model_string_for_api": "Qwen/Qwen1.5-14B-Chat",
        "context_length": 32768,
        "description": "Large-scale Qwen model optimized for long-context conversations.",
        "modeltype": "Chat",
        "response_time": "Slower",
        "cost": "High",
        "known_for": "Handling long-context conversations",
        "specialty": "Efficient for advanced conversational tasks",
        "use_suggestion": "Great for business-level chat applications and technical support."
    },
    {
        "organization": "Qwen",
        "model_name": "Qwen 1.5 Chat (72B)",
        "model_string_for_api": "Qwen/Qwen1.5-72B-Chat",
        "context_length": 4096,
        "description": "Massive 72B parameter model optimized for chat tasks.",
        "modeltype": "Chat",
        "response_time": "Slower",
        "cost": "High",
        "known_for": "Massive chat model for complex tasks",
        "specialty": "Handling extremely large conversations",
        "use_suggestion": "Ideal for enterprise-grade support or complex technical chatbots."
    },
    {
        "organization": "Snorkel AI",
        "model_name": "Snorkel Mistral PairRM DPO (7B)",
        "model_string_for_api": "snorkelai/Snorkel-Mistral-PairRM-DPO",
        "context_length": 32768,
        "description": "Snorkel's PairRM DPO model based on Mistral for chat.",
        "modeltype": "Chat",
        "response_time": "Medium",
        "cost": "Medium",
        "known_for": "PairRM DPO model for efficient chat",
        "specialty": "Handling multitasking and deeper context conversations",
        "use_suggestion": "Use for sophisticated chatbots or personal assistants with high interaction."
    },
    {
        "organization": "Stanford",
        "model_name": "Alpaca (7B)",
        "model_string_for_api": "togethercomputer/alpaca-7b",
        "context_length": 2048,
        "description": "Stanford's Alpaca model for instruction-based conversational tasks.",
        "modeltype": "Chat",
        "response_time": "Faster",
        "cost": "Cheaper",
        "known_for": "Alpaca model for instruction-based conversations",
        "specialty": "Handling lightweight instruction tasks",
        "use_suggestion": "Great for academic or tutorial chatbots."
    },
    {
        "organization": "Teknium",
        "model_name": "OpenHermes 2 Mistral (7B)",
        "model_string_for_api": "teknium/OpenHermes-2-Mistral-7B",
        "context_length": 8192,
        "description": "Teknium's Mistral-based OpenHermes model for efficient chat tasks.",
        "modeltype": "Chat",
        "response_time": "Faster",
        "cost": "Cheaper",
        "known_for": "Efficient conversational tasks",
        "specialty": "General-purpose chat with fast responses",
        "use_suggestion": "Perfect for quick customer support or interactive assistants."
    },
    {
        "organization": "Teknium",
        "model_name": "OpenHermes 2.5 Mistral (7B)",
        "model_string_for_api": "teknium/OpenHermes-2p5-Mistral-7B",
        "context_length": 8192,
        "description": "Teknium's enhanced OpenHermes 2.5 model for complex conversations.",
        "modeltype": "Chat",
        "response_time": "Faster",
        "cost": "Cheaper",
        "known_for": "Enhanced OpenHermes model",
        "specialty": "Handling more complex conversational tasks",
        "use_suggestion": "Great for multitasking chatbots with a need for context awareness."
    },




    {
        "organization": "TII UAE",
        "model_name": "Falcon Instruct (40B)",
        "model_string_for_api": "togethercomputer/falcon-40b-instruct",
        "context_length": 2048,
        "description": "Falcon model optimized for instruction-based conversational tasks.",
        "modeltype": "Chat",
        "response_time": "Medium",
        "cost": "High",
        "known_for": "Falcon's instruction-based chat",
        "specialty": "Handling instruction-based conversational tasks",
        "use_suggestion": "Ideal for handling tutorials and long-form conversations."
    },
    {
        "organization": "TII UAE",
        "model_name": "Falcon Instruct (7B)",
        "model_string_for_api": "togethercomputer/falcon-7b-instruct",
        "context_length": 2048,
        "description": "Smaller version of Falcon tuned for instruction and chat.",
        "modeltype": "Chat",
        "response_time": "Faster",
        "cost": "Cheaper",
        "known_for": "Instruction-based tasks",
        "specialty": "Handling smaller chat tasks efficiently",
        "use_suggestion": "Perfect for lightweight chat apps and simple instructions."
    },
    {
        "organization": "Together",
        "model_name": "LLaMA-2 Instruct (7B) 32K",
        "model_string_for_api": "togethercomputer/Llama-2-7B-32K-Instruct",
        "context_length": 32768,
        "description": "Together's LLaMA-2-7B with a large 32K context window.",
        "modeltype": "Chat",
        "response_time": "Medium",
        "cost": "Medium",
        "known_for": "Large 32K context support",
        "specialty": "Handling medium to large conversational tasks",
        "use_suggestion": "Ideal for managing medium to long-form conversations or instructions."
    },
    {
        "organization": "Together",
        "model_name": "RedPajama INCITE Chat (3B)",
        "model_string_for_api": "togethercomputer/RedPajama-INCITE-Chat-3B-v1",
        "context_length": 2048,
        "description": "RedPajama INCITE 3B model optimized for chat interactions.",
        "modeltype": "Chat",
        "response_time": "Faster",
        "cost": "Cheaper",
        "known_for": "Optimized for chat interactions",
        "specialty": "Handling lightweight conversations",
        "use_suggestion": "Good for casual conversations or small customer service chatbots."
    },
    {
        "organization": "Together",
        "model_name": "RedPajama INCITE Chat (7B)",
        "model_string_for_api": "togethercomputer/RedPajama-INCITE-7B-Chat",
        "context_length": 2048,
        "description": "Larger RedPajama model optimized for conversational tasks.",
        "modeltype": "Chat",
        "response_time": "Faster",
        "cost": "Medium",
        "known_for": "Handling conversational tasks efficiently",
        "specialty": "General-purpose chat with larger context",
        "use_suggestion": "Ideal for customer service or handling casual conversations."
    },
    {
        "organization": "Together",
        "model_name": "StripedHyena Nous (7B)",
        "model_string_for_api": "togethercomputer/StripedHyena-Nous-7B",
        "context_length": 32768,
        "description": "Together's StripedHyena Nous model with enhanced chat performance.",
        "modeltype": "Chat",
        "response_time": "Medium",
        "cost": "Medium",
        "known_for": "Handling enhanced chat tasks",
        "specialty": "Complex conversational tasks with multitasking support",
        "use_suggestion": "Great for business chatbots or technical support with high interaction."
    },
    {
        "organization": "Undi95",
        "model_name": "ReMM SLERP L2 (13B)",
        "model_string_for_api": "Undi95/ReMM-SLERP-L2-13B",
        "context_length": 4096,
        "description": "SLERP L2 model optimized for long-range conversations.",
        "modeltype": "Chat",
        "response_time": "Medium",
        "cost": "Medium",
        "known_for": "Handling long-range conversations",
        "specialty": "Handling larger conversations with advanced topics",
        "use_suggestion": "Perfect for long, in-depth chat applications or technical discussions."
    },
    {
        "organization": "Undi95",
        "model_name": "Toppy M (7B)",
        "model_string_for_api": "Undi95/Toppy-M-7B",
        "context_length": 4096,
        "description": "Toppy M model designed for efficient conversational tasks.",
        "modeltype": "Chat",
        "response_time": "Faster",
        "cost": "Cheaper",
        "known_for": "Efficient conversational tasks",
        "specialty": "Handling smaller chat interactions",
        "use_suggestion": "Good for small talk, jokes, or everyday chatbot interactions."
    },
    {
        "organization": "WizardLM",
        "model_name": "WizardLM v1.2 (13B)",
        "model_string_for_api": "WizardLM/WizardLM-13B-V1.2",
        "context_length": 4096,
        "description": "WizardLM's v1.2 model with optimized outputs for chat.",
        "modeltype": "Chat",
        "response_time": "Medium",
        "cost": "Medium",
        "known_for": "Optimized outputs for chat",
        "specialty": "General-purpose chat with focus on advanced tasks",
        "use_suggestion": "Ideal for versatile chat applications requiring complex conversations."
    },






    {
        "organization": "Upstage",
        "model_name": "Upstage SOLAR Instruct v1 (11B)",
        "model_string_for_api": "upstage/SOLAR-10.7B-Instruct-v1.0",
        "context_length": 4096,
        "description": "Upstage SOLAR model designed for instruction-based chat tasks.",
        "modeltype": "Chat",
        "response_time": "Medium",
        "cost": "Medium",
        "known_for": "Instruction-based chat tasks",
        "specialty": "Handling medium to large instruction-based conversations",
        "use_suggestion": "Use for academic instruction, tutoring, or interactive chat."
    },
    {
        "organization": "OpenAI",
        "model_name": "GPT-4",
        "model_string_for_api": "gpt-4",
        "context_length": 8192,
        "description": "OpenAI's GPT-4 model for versatile conversational tasks.",
        "modeltype": "Chat",
        "response_time": "Medium",
        "cost": "High",
        "known_for": "Versatile conversational tasks",
        "specialty": "Handling complex, advanced conversational tasks",
        "use_suggestion": "Perfect for in-depth discussions, content generation, or problem solving."
    },





    {
        "organization": "OpenAI",
        "model_name": "GPT-4 Turbo",
        "model_string_for_api": "gpt-4-turbo",
        "context_length": 8192,
        "description": "Optimized version of GPT-4 for faster interactions.",
        "modeltype": "Chat",
        "response_time": "Faster",
        "cost": "Medium",
        "known_for": "Faster interactions with GPT-4 capabilities",
        "specialty": "Handling fast and advanced conversational tasks",
        "use_suggestion": "Great for chatbots, technical support, and real-time interactions."
    },
    {
        "organization": "OpenAI",
        "model_name": "GPT-4 (0613)",
        "model_string_for_api": "gpt-4-0613",
        "context_length": 8192,
        "description": "GPT-4 variant with function calling support.",
        "modeltype": "Chat",
        "response_time": "Medium",
        "cost": "High",
        "known_for": "Function calling support",
        "specialty": "Handling complex conversations with function calling abilities",
        "use_suggestion": "Perfect for applications involving API calls and interactive tasks."
    },
    {
        "organization": "OpenAI",
        "model_name": "GPT-4 (32K)",
        "model_string_for_api": "gpt-4-32k",
        "context_length": 32768,
        "description": "GPT-4 model with extended context window for long inputs.",
        "modeltype": "Chat",
        "response_time": "Slower",
        "cost": "High",
        "known_for": "Extended context window for long inputs",
        "specialty": "Handling long-form conversations",
        "use_suggestion": "Ideal for detailed projects, long-form discussions, or advanced customer service."
    },
    {
        "organization": "OpenAI",
        "model_name": "GPT-4 (32K 0613)",
        "model_string_for_api": "gpt-4-32k-0613",
        "context_length": 32768,
        "description": "GPT-4 32K variant with function calling support.",
        "modeltype": "Chat",
        "response_time": "Slower",
        "cost": "High",
        "known_for": "Function calling and extended context",
        "specialty": "Handling long and complex conversations",
        "use_suggestion": "Best for advanced customer service, long-form discussions, and function calling tasks."
    },
    {
        "organization": "OpenAI",
        "model_name": "GPT-3.5 Turbo (0125)",
        "model_string_for_api": "gpt-3.5-turbo-0125",
        "context_length": 4096,
        "description": "GPT-3.5 Turbo optimized for efficient conversational tasks.",
        "modeltype": "Chat",
        "response_time": "Faster",
        "cost": "Cheaper",
        "known_for": "Efficient conversational tasks",
        "specialty": "Fast interactions for small to medium conversations",
        "use_suggestion": "Great for chatbots, quick responses, or lightweight interactive tasks."
    },
    {
        "organization": "OpenAI",
        "model_name": "GPT-3.5 Turbo",
        "model_string_for_api": "gpt-3.5-turbo",
        "context_length": 4096,
        "description": "GPT-3.5 Turbo for fast and versatile conversations.",
        "modeltype": "Chat",
        "response_time": "Faster",
        "cost": "Cheaper",
        "known_for": "Fast and versatile conversations",
        "specialty": "Handling everyday chat tasks",
        "use_suggestion": "Perfect for customer support, quick chat, and interactive tools."
    },
    {
        "organization": "OpenAI",
        "model_name": "GPT-3.5 Turbo (1106)",
        "model_string_for_api": "gpt-3.5-turbo-1106",
        "context_length": 4096,
        "description": "GPT-3.5 Turbo variant optimized for chat tasks.",
        "modeltype": "Chat",
        "response_time": "Faster",
        "cost": "Medium",
        "known_for": "Optimized for chat tasks",
        "specialty": "Handling efficient chat with faster outputs",
        "use_suggestion": "Great for customer service bots or technical troubleshooting."
    },
    {
        "organization": "OpenAI",
        "model_name": "GPT-3.5 Turbo Instruct",
        "model_string_for_api": "gpt-3.5-turbo-instruct",
        "context_length": 4096,
        "description": "Instruction-based variant of GPT-3.5 Turbo.",
        "modeltype": "Chat",
        "response_time": "Medium",
        "cost": "Medium",
        "known_for": "Instruction-based tasks",
        "specialty": "Handling instructional interactions",
        "use_suggestion": "Use for tutoring, technical documentation, or step-by-step guidance."
    },
    {
        "organization": "OpenAI",
        "model_name": "GPT-3.5 Turbo (16K)",
        "model_string_for_api": "gpt-3.5-turbo-16k",
        "context_length": 16384,
        "description": "GPT-3.5 Turbo with extended context window.",
        "modeltype": "Chat",
        "response_time": "Medium",
        "cost": "Medium",
        "known_for": "Extended context window",
        "specialty": "Handling longer conversations",
        "use_suggestion": "Best for managing multi-turn dialogues or long customer queries."
    },
    {
        "organization": "OpenAI",
        "model_name": "GPT-3.5 Turbo (0613)",
        "model_string_for_api": "gpt-3.5-turbo-0613",
        "context_length": 4096,
        "description": "GPT-3.5 Turbo variant with function calling support.",
        "modeltype": "Chat",
        "response_time": "Faster",
        "cost": "Medium",
        "known_for": "Function calling support",
        "specialty": "Handling API interactions and conversational tasks",
        "use_suggestion": "Great for integrating function calling in chat applications."
    },
    {
        "organization": "OpenAI",
        "model_name": "GPT-3.5 Turbo (16K 0613)",
        "model_string_for_api": "gpt-3.5-turbo-16k-0613",
        "context_length": 16384,
        "description": "GPT-3.5 Turbo 16K variant with function calling support.",
        "modeltype": "Chat",
        "response_time": "Medium",
        "cost": "Medium",
        "known_for": "Extended context and function calling",
        "specialty": "Handling long-form conversations with function calling",
        "use_suggestion": "Ideal for complex applications needing long dialogues and external function interactions."
    },






    {
        "organization": "OpenAI",
        "model_name": "GPT-4o",
        "model_string_for_api": "gpt-4o",
        "context_length": 8192,
        "description": "OpenAI's optimized GPT-4o for fast and advanced chat tasks.",
        "modeltype": "Chat",
        "response_time": "Medium",
        "cost": "High",
        "known_for": "Optimized GPT-4 for fast and advanced chat tasks",
        "specialty": "Handling complex, real-time conversations",
        "use_suggestion": "Use for advanced AI assistants, problem solving, or customer support."
    },
    {
        "organization": "OpenAI",
        "model_name": "GPT-4o Mini",
        "model_string_for_api": "gpt-4o-mini",
        "context_length": 128000,
        "description": "Mini variant of GPT-4o with massive context length support.",
        "modeltype": "Chat",
        "response_time": "Faster",
        "cost": "Medium",
        "known_for": "Compact GPT-4 model with massive context support",
        "specialty": "Handling fast, real-time interactions with large inputs",
        "use_suggestion": "Best for chat-based apps requiring speed and long context windows."
    },
    {
        "organization": "Anthropic",
        "model_name": "Claude 3 Opus (20240229)",
        "model_string_for_api": "claude-3-opus-20240229",
        "context_length": 8192,
        "description": "Anthropic's Claude 3 Opus optimized for conversational tasks.",
        "modeltype": "Chat",
        "response_time": "Medium",
        "cost": "High",
        "known_for": "Anthropic's advanced conversational model",
        "specialty": "Handling versatile conversational tasks",
        "use_suggestion": "Great for complex conversations, deep discussions, or business chat applications."
    },
    {
        "organization": "Anthropic",
        "model_name": "Claude 3 Sonnet (20240229)",
        "model_string_for_api": "claude-3-sonnet-20240229",
        "context_length": 8192,
        "description": "Claude 3 Sonnet, specialized for chat and conversational tasks.",
        "modeltype": "Chat",
        "response_time": "Medium",
        "cost": "High",
        "known_for": "Conversational tasks with a creative focus",
        "specialty": "Handling conversational creativity and complex responses",
        "use_suggestion": "Perfect for content generation, creative writing, or brainstorming. GPT-4"
    },
    {
        "organization": "Anthropic",
        "model_name": "Claude 3 Haiku (20240307)",
        "model_string_for_api": "claude-3-haiku-20240307",
        "context_length": 8192,
        "description": "Claude 3 Haiku, designed for quick chat-based interactions.",
        "modeltype": "Chat",
        "response_time": "Faster",
        "cost": "Medium",
        "known_for": "Quick chat interactions",
        "specialty": "Handling small, fast conversations with creative flair",
        "use_suggestion": "Use for creative chat, quick idea generation, or casual interactions."
    }
]

export default availableModels